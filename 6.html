<html>
<head>
<title>Model Assessments</title>
<style>
body {
background-image: url(m16.jpg);
   background-repeat: no-repeat;
    background-position: center;
	
      background-size: 100% 100%;
	  }
</style>	  
</head> 
<body bgcolor=#A9A9A9 size=20>
<u><font size="+4"><p style="text-align:center;color:#2F4F4F"> Model Assessments</p></font></u>
<font size="+2"><center><p style="text-align:center;color:D2691E">
Classification machine learning models can be validated by accuracy estimation techniques like the Holdout method, which splits the data in a training and test set (conventionally 2/3 training set and 1/3 test set designation) and evaluates the performance of the training model on the test set. In comparison, the N-fold-cross-validation method randomly splits the data in k subsets where the k-1 instances of the data are used to train the model while the kth instance is used to test the predictive ability of the training model. In addition to the holdout and cross-validation methods, bootstrap, which samples n instances with replacement from the dataset, can be used to assess model accuracy
.<br>

In addition to overall accuracy, investigators frequently report sensitivity and specificity meaning True Positive Rate (TPR) and True Negative Rate (TNR) respectively. Similarly, investigators sometimes report the False Positive Rate (FPR) as well as the False Negative Rate (FNR). However, these rates are ratios that fail to reveal their numerators and denominators. The Total Operating Characteristic (TOC) is an effective method to express a model’s diagnostic ability. TOC shows the numerators and denominators of the previously mentioned rates, thus TOC provides more information than the commonly used Receiver operating characteristic (ROC) and ROC’s associated Area Under the Curve (AUC).<br>
</p>

<p style="text-align:center;color:red"> <a href="index.html"> Home</a> <p>
